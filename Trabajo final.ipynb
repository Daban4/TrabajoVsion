{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f788c05e-021f-4d03-8cbd-a04b73fe7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291795fb-f0a1-488a-969b-186297453e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ideas:\n",
    "- ampliar rango dinamico \n",
    "- Podriamos hacer homogenizar el histograma\n",
    "- Filtro de suavizado \n",
    "- Filtro de sal y pimienta(sobre todo sal y pimienta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e2fa6b-13fc-4ea7-8286-a0f571e937f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "como subir documentos\n",
    "git pull\n",
    "modificar\n",
    "git add . ( o nombre del archivo)\n",
    "git commit -m \"descripcion de los cambios realizados\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7af3546-4cbc-409d-9729-c14fb9cc375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 253\n"
     ]
    }
   ],
   "source": [
    "imagen = cv2.imread('cat_dog_100/train/dog/dog.10002.jpg', 0)\n",
    "print(np.min(imagen), np.max(imagen));\n",
    "imagenAmpliada = ampliarRangoDin(imagen)\n",
    "cv2.imshow('imagen original', imagen)\n",
    "cv2.imshow('imagen ampliada', imagenAmpliada)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2e1da3-608b-4bbf-946d-090b463e38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ampliarRangoDin(imagen):\n",
    "    imagen = np.float32(imagen);\n",
    "    imagenPlana = imagen.reshape(1, -1)\n",
    "    pixelesOrd = np.sort(imagenPlana)\n",
    "    al = np.unique(pixelesOrd)[5]\n",
    "    ah = np.unique(pixelesOrd)[-6]\n",
    "    imagenAmpliada = (imagen - al) * (255 /(ah - al))\n",
    "    np.clip(imagenAmpliada, 0, 255)\n",
    "    imagenAmpliada = np.uint8(np.clip(imagenAmpliada, 0, 255))\n",
    "    return imagenAmpliada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af3c3704-c38c-4249-9815-cc9919d3ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import median_filter\n",
    "def filtroMediana (imagen, n = None):\n",
    "    imagen = np.float32(imagen)\n",
    "    if (n is None):\n",
    "        n = 3\n",
    "    ndiv = n //2\n",
    "    imagen_filtrada = np.zeros_like(imagen)\n",
    "    imagen_ampliada = cv2.copyMakeBorder(imagen, ndiv, ndiv, ndiv, ndiv, cv2.BORDER_REPLICATE)\n",
    "    ventana = n * 2 + 1\n",
    "    imagen_filtrada = median_filter(imagen, size=ventana)\n",
    "\n",
    "    imagen_filtrada = np.uint8(imagen_filtrada)\n",
    "    return imagen_filtrada\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b72f275-61eb-4a45-acab-eaf6f6b3452b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtroMediana' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m imagen \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_dog_100/train/dog/dog.10095.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m imagen_sp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8(\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m random_noise(imagen, mode\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms&p\u001b[39m\u001b[38;5;124m'\u001b[39m, amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m imagenFiltradaMedia \u001b[38;5;241m=\u001b[39m (\u001b[43mfiltroMediana\u001b[49m(imagen_sp))\n\u001b[0;32m      6\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagen original\u001b[39m\u001b[38;5;124m'\u001b[39m, imagen_sp)\n\u001b[0;32m      7\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagen filtrada\u001b[39m\u001b[38;5;124m'\u001b[39m, imagenFiltradaMedia)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtroMediana' is not defined"
     ]
    }
   ],
   "source": [
    "from skimage.util import random_noise\n",
    "\n",
    "imagen = cv2.imread('cat_dog_100/train/dog/dog.10095.jpg', 0)\n",
    "imagen_sp = np.uint8(255 * random_noise(imagen, mode= 's&p', amount = 0.1))\n",
    "imagenFiltradaMedia = (filtroMediana(imagen_sp))\n",
    "cv2.imshow('imagen original', imagen_sp)\n",
    "cv2.imshow('imagen filtrada', imagenFiltradaMedia)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91e9030c-e5d9-4baa-8ad4-054f0d09a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionar imagenes\n",
    "imagen1 = cv2.imread('cat_dog_100/train/dog/dog.10095.jpg', 0)\n",
    "imagen2 = cv2.imread('cat_dog_100/train/dog/dog.10005.jpg', 0)\n",
    "imagen3 = cv2.imread('cat_dog_100/train/dog/dog.10015.jpg', 0)\n",
    "cv2.imshow('imagen 1', imagen1)\n",
    "cv2.imshow('imagen 2', imagen2)\n",
    "cv2.imshow('imagen 3', imagen3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "imagenRed1 = cv2.resize(imagen1, (128, 128))\n",
    "imagenRed2 = cv2.resize(imagen2, (128, 128))\n",
    "imagenRed3 = cv2.resize(imagen3, (128, 128))\n",
    "cv2.imshow('imagen 1', imagenRed1)\n",
    "cv2.imshow('imagen 2', imagenRed2)\n",
    "cv2.imshow('imagen 3', imagenRed3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c639ba5e-a72a-4a3d-95b4-82a33f3c8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redimensionar(imagen):\n",
    "    imagenRed = cv2.resize(imagen, (128, 128))\n",
    "    return imagenRed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75c78530-2dd4-4556-8ee1-90972a0bb875",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    camino = 'cat_dog_100/train/dog/dog.' + str(10000 + i + 1) + '.jpg'\n",
    "    imagen1 = cv2.imread(camino, 0)\n",
    "    # Muestra la imagen en una ventana con un nombre único\n",
    "    cv2.imshow(f'imagen_{i}', imagen1)  # f'imagen_{i}' genera nombres como 'imagen_0', 'imagen_1', etc.\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84dc4326-d3ca-4604-9ca0-b3d228ad8303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([3, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6e564-e9f1-47b0-be09-e52e5df8b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bordes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adcb7a59-6672-48ab-9b39-5267178e3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro(imagen, mascara):\n",
    "    imagen = np.float32(imagen)\n",
    "    imagen_f = cv2.filter2D(imagen, -1, mascara)\n",
    "    return imagen_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aecd3563-ba45-4005-93cd-0a516076c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente(imagen):\n",
    "    m_g_x = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]] )\n",
    "    m_g_y = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    Ix = filtro(imagen, m_g_x)\n",
    "    Iy = filtro(imagen, m_g_y)\n",
    "    E = np.sqrt(Ix**2 + Iy**2)\n",
    "    Phi = np.arctan2(Ix, Iy)\n",
    "    return E, Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5192c8a-c992-4b42-9181-61133004d113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b1cc554-7e22-4a82-ba74-21af1b8b729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen = cv2.imread('cat_dog_100/train/dog/dog.10095.jpg', 0)\n",
    "E, phi = gradiente(imagen)\n",
    "\n",
    "cv2.imshow('Magnitudes',E/E.max())\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f9f7296-5e5a-415f-97f7-6a62953e2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "filename = 'cat_dog_100/train/dog/dog.10009.jpg'\n",
    "img = cv.imread(filename)\n",
    "img = redimensionar(img)\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "gray = filtroMediana(gray)\n",
    "dst = cv.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]= 255\n",
    "\n",
    "cv.imshow('dst',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e46191-0381-413d-9edb-99abba281b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Probar a umbralizar, como en la imagen del platano, sino hay mucha mierda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987ec98d-3fb1-413a-83c0-adf9ffefdb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagen_media_chat(imagen, etiquetas, centros):\n",
    "    print(centros)\n",
    "    etiquetas = etiquetas.reshape(imagen.shape)\n",
    "    imagen_segmentada = np.zeros_like(imagen, dtype=np.float32)    \n",
    "    for i, centro in enumerate(centros):\n",
    "        imagen_segmentada[etiquetas == i] = centro\n",
    "    \n",
    "    return imagen_segmentada.astype(np.uint8)  # Convertir a uint8 para visualización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8591a37d-5a29-4e95-a510-5c121dd9f853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112.41979911]\n",
      " [220.94699711]\n",
      " [169.51025449]\n",
      " [ 70.37752414]\n",
      " [138.31928247]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "imagen = cv2.imread('cat_dog_100/train/dog/dog.10009.jpg', 0)\n",
    "kmeans = KMeans(n_clusters = 5, n_init=10)\n",
    "kmeans.fit(imagen.reshape(-1, 1))\n",
    "centros = kmeans.cluster_centers_\n",
    "etiquetas = kmeans.labels_\n",
    "imagenMedia = imagen_media_chat(imagen, etiquetas, centros)\n",
    "cv2.imshow('Imagen media', imagenMedia)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53aafce6-c490-4116-b7ea-1fcde26b72a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_caracteristicas_hog(imagen, tamano_celda=16, num_bins=9):\n",
    "    # nos aseguramos de que la imagen esté en escala de grises\n",
    "    if len(imagen.shape) > 2:\n",
    "        raise ValueError(\"La imagen de entrada debe estar en escala de grises\")\n",
    "\n",
    "    # Paso 1: Calculamos el gradiente usando filtros [-1, 0, 1]\n",
    "    grad_x = cv2.filter2D(imagen, cv2.CV_32F, np.array([[-1, 0, 1]]))\n",
    "    grad_y = cv2.filter2D(imagen, cv2.CV_32F, np.array([[-1], [0], [1]]))\n",
    "\n",
    "    # Paso 2: Calculamos la magnitud y orientación del gradiente\n",
    "    magnitud = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    orientacion = np.arctan2(grad_y, grad_x) * (180 / np.pi) % 180\n",
    "\n",
    "    # Paso 3: Dividimos la imagen en celdas\n",
    "    h, w = imagen.shape\n",
    "    celdas_x = w // tamano_celda\n",
    "    celdas_y = h // tamano_celda\n",
    "\n",
    "    caracteristicas_hog = []\n",
    "\n",
    "    # Paso 4: Calculamos histogramas para cada celda\n",
    "    for i in range(celdas_y):\n",
    "        for j in range(celdas_x):\n",
    "            # Extraemos la región de la celda\n",
    "            celda_mag = magnitud[i * tamano_celda:(i + 1) * tamano_celda, j * tamano_celda:(j + 1) * tamano_celda]\n",
    "            celda_ori = orientacion[i * tamano_celda:(i + 1) * tamano_celda, j * tamano_celda:(j + 1) * tamano_celda]\n",
    "\n",
    "            # Creamos el histograma para la celda\n",
    "            histograma = np.zeros(num_bins, dtype=np.float32)\n",
    "            ancho_bin = 180 / num_bins\n",
    "\n",
    "            for m in range(celda_mag.shape[0]):\n",
    "                for n in range(celda_mag.shape[1]):\n",
    "                    # Determinar el bin para cada píxel\n",
    "                    indice_bin = int(celda_ori[m, n] // ancho_bin) % num_bins\n",
    "                    histograma[indice_bin] += celda_mag[m, n]\n",
    "\n",
    "            # Normalizamos el histograma (norma L2)\n",
    "            norma = np.linalg.norm(histograma)\n",
    "            if norma != 0:\n",
    "                histograma /= norma\n",
    "\n",
    "            caracteristicas_hog.append(histograma)\n",
    "\n",
    "    # Paso 5: Concatenamos todos los histogramas para formar el vector de características\n",
    "    caracteristicas_hog = np.concatenate(caracteristicas_hog)\n",
    "\n",
    "    return caracteristicas_hog\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7ced515-f8fc-4d92-a289-04ec7413277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 41.34197557]\n",
      " [126.91956672]\n",
      " [190.72493947]\n",
      " [ 87.14419795]\n",
      " [161.59717076]]\n",
      "Vector de características combinado: (17460,)\n"
     ]
    }
   ],
   "source": [
    "def pipeline_completo(imagen_path):\n",
    "    # Cargar imagen en escala de grises\n",
    "    imagen = cv2.imread(imagen_path, cv2.IMREAD_GRAYSCALE)\n",
    "    imagen = cv2.resize(imagen, (128, 128))  # Redimensionar para consistencia\n",
    "    \n",
    "    # 1. Preprocesamiento\n",
    "    imagen_ampliada = ampliarRangoDin(imagen)\n",
    "    imagen_suavizada = filtroMediana(imagen_ampliada)\n",
    "    \n",
    "    # 2. Extracción de características HOG\n",
    "    caracteristicas_hog = calcular_caracteristicas_hog(imagen_suavizada, tamano_celda=16, num_bins=9)\n",
    "    \n",
    "    # 3. Puntos clave (Harris)\n",
    "    gray = np.float32(imagen_suavizada)\n",
    "    puntos_harris = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "    puntos_harris = puntos_harris.flatten()[:500]  # Limitar número de puntos clave\n",
    "    \n",
    "    # 4. Segmentación por K-means\n",
    "    kmeans = KMeans(n_clusters=5, n_init=10)\n",
    "    kmeans.fit(imagen_suavizada.reshape(-1, 1))\n",
    "    centros = kmeans.cluster_centers_\n",
    "    etiquetas = kmeans.labels_\n",
    "    imagen_segmentada = imagen_media_chat(imagen_suavizada, etiquetas, centros).flatten()\n",
    "    \n",
    "    # 5. Combinar características\n",
    "    caracteristicas_combinadas = np.hstack([caracteristicas_hog, puntos_harris, imagen_segmentada])\n",
    "    \n",
    "    return caracteristicas_combinadas\n",
    "\n",
    "# Ejemplo de uso\n",
    "imagen_path = 'cat_dog_100/train/dog/dog.10095.jpg'\n",
    "caracteristicas = pipeline_completo(imagen_path)\n",
    "print(f\"Vector de características combinado: {caracteristicas.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01dac4e2-90df-4576-9a09-95ef61e30604",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [17460, 166000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaracteristicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metiquetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Crear y entrenar el modelo\u001b[39;00m\n\u001b[0;32m     12\u001b[0m modelo \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311ml\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311ml\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2657\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2662\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [17460, 166000]"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(caracteristicas, etiquetas, test_size=0.15, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "modelo = SVC(kernel='linear', random_state=42)\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "predicciones = modelo.predict(X_test)\n",
    "print(f\"Precisión del modelo: {accuracy_score(y_test, predicciones):.2f}\")\n",
    "\n",
    "modelo = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "predicciones = modelo.predict(X_test)\n",
    "print(f\"Precisión del modelo: {accuracy_score(y_test, predicciones):.2f}\")\n",
    "\n",
    "print(confusion_matrix(y_test, predicciones))\n",
    "print(classification_report(y_test, predicciones))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "nueva_imagen = cv2.imread('cat_dog_100/train/dog/dog.10095.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "caracteristicas_nueva = calcular_caracteristicas_comb(nueva_imagen)\n",
    "prediccion = modelo.predict([caracteristicas_nueva])\n",
    "\n",
    "print(\"Es un perro\" if prediccion[0] == 1 else \"Es un gato\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84eb9a40-0d78-4620-b009-99630b0a0d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('cat_dog_100/train/dog/dog.10095.jpg')\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "sift = cv.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    "\n",
    "img=cv.drawKeypoints(gray,kp,img)\n",
    "\n",
    "cv.imwrite('sift_keypoints.jpg',img)\n",
    "          \n",
    "cv.imshow('dst',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
